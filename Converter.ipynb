{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi there! The purpose of this notebook - develop and test YOlO2PyTorch conveter before to pack it inside .py scripts. <br>\n",
    "Supported YOLO version:\n",
    "* YOLO v3\n",
    "\n",
    "Based on the tutorials: https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/\n",
    "\n",
    "Additional info:\n",
    "* Cfg parameters meaning: https://github.com/AlexeyAB/darknet/wiki/CFG-Parameters-in-the-different-layers\n",
    "* ```net``` section cfg parameters meaning: https://github.com/AlexeyAB/darknet/wiki/CFG-Parameters-in-the-%5Bnet%5D-section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmptyLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmptyLayer, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cfg(file_path):\n",
    "    \"\"\"\n",
    "    Parse .cfg darknet file with neural net architecture.\n",
    "    Input:\n",
    "        Path to a .cfg file\n",
    "    Output:\n",
    "        Returns a list of blocks. Each blocks describes a block in the neural\n",
    "        network to be built. Block is represented as a dictionary in the list\n",
    "\n",
    "    \"\"\"\n",
    "    # Split cfg files to the lines\n",
    "    cfg_file = open(file_path, 'r')\n",
    "    lines = cfg_file.read().splitlines()\n",
    "    lines = [x.rstrip().lstrip() for x in lines if (x != '') and ('#' not in x)]\n",
    "    blocks = []\n",
    "    # Pack it into list of dict\n",
    "    for line in lines:\n",
    "        if line[0] == '[':                             # [ symbols means new block announcement\n",
    "            block = {}\n",
    "            block['type'] = line[1:-1]\n",
    "            blocks.append(block)\n",
    "        else:\n",
    "            key, value = line.split('=')\n",
    "            block[key.rstrip()] = value.lstrip()       # rsplit/lsplit in case user type ' = ' instead of '='    \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modules(blocks):\n",
    "    '''\n",
    "    Create PyTorch model based on parsed darknet model blocks\n",
    "    Input:\n",
    "        'blocks' list from the 'parse_cfg' function\n",
    "    Output:\n",
    "        PyTorch ModuleList object\n",
    "    '''\n",
    "    # Setting up variables\n",
    "    module_list = nn.ModuleList()\n",
    "    prev_filters = 3               # Track previous layer depth. Initial depth - 3 (RGB image)\n",
    "    output_filters = []            # Track all ???\n",
    "    \n",
    "    # Capture general information about a net\n",
    "    net_info = blocks[0]\n",
    "    \n",
    "    for idx, x in enumerate(blocks[1:]):\n",
    "        module = nn.Sequential()\n",
    "        \n",
    "        ## CONVOLUTIONAL LAYERS\n",
    "        # Get info about a convolutional layer\n",
    "        if x['type'] == 'convolutional':\n",
    "            try:\n",
    "                batch_norm = int(x['batch_normalize'])\n",
    "                bias = False\n",
    "            except:\n",
    "                batch_norm = 0\n",
    "                bias = True\n",
    "            activation = x['activation']    \n",
    "            filters = int(x['filters'])\n",
    "            kernel_size = int(x['size'])\n",
    "            stride = int(x['stride'])\n",
    "            padding = int(x['pad'])\n",
    "            \n",
    "            # Convert padding values according to AlexeyAB's wiki page\n",
    "            if padding == 1:\n",
    "                padding = kernel_size // 2   \n",
    "            else:\n",
    "                padding = padding\n",
    "                \n",
    "            # Create PyTorch convolutional layer\n",
    "            conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, padding, bias=bias)\n",
    "            module.add_module('conv_{}'.format(idx), conv)\n",
    "        \n",
    "            # Add BatchNorm layer\n",
    "            if batch_norm:\n",
    "                bn = nn.BatchNorm2d(filters)\n",
    "                module.add_module('batch_norm_{}'.format(idx), bn)\n",
    "\n",
    "            # Add Activation layer\n",
    "            if activation == 'leaky':\n",
    "                activ = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "                module.add_module('leaky_ReLu_{}'.format(idx), activ)\n",
    "            else: # linear case\n",
    "                pass                                                            #???\n",
    "            \n",
    "        ## UPSAMPLE LAYER\n",
    "        elif x['type'] == 'upsample':\n",
    "            factor = int(x['stride'])\n",
    "            upsample = nn.Upsample(scale_factor=factor, mode='bilinear')\n",
    "            module.add_module('upsample_{}'.format(idx), upsample)\n",
    "        \n",
    "        ## SHORTCUT LAYER\n",
    "        elif x['type'] == 'shortcut':\n",
    "            shortcut = EmptyLayer()\n",
    "            module.add_module('shortcut_{}'.format(idx), shortcut)\n",
    "        \n",
    "        ## ROUTE LAYER\n",
    "        # layers = -1, 61 - layers that will be concatenated, output: W x H x C_layer_1 + C_layer_2\n",
    "        # if index < 0, then it is relative layer number (-1 means previous layer)\n",
    "        # if index >= 0, then it is absolute layer number\n",
    "\n",
    "        elif x['type'] == 'route':\n",
    "            layers = list(map(int, x['layers'].split(',')))\n",
    "            # ???\n",
    "            \n",
    "        \n",
    "        ## YOLO LAYER\n",
    "        elif x['type'] == 'yolo':\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('Unknown layer detected!')\n",
    "            \n",
    "\n",
    "        ## UPDATE VARIABLES\n",
    "        module_list.append(module)\n",
    "        prev_filters = filters\n",
    "        output_filters.append(filters)\n",
    "        \n",
    "    return module_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = './detector/cfg/yolov3.cfg'\n",
    "parse_result = parse_cfg(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Sequential(\n",
       "    (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_0): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (4): Sequential()\n",
       "  (5): Sequential(\n",
       "    (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_6): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (8): Sequential()\n",
       "  (9): Sequential(\n",
       "    (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_9): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (10): Sequential(\n",
       "    (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_10): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (11): Sequential()\n",
       "  (12): Sequential(\n",
       "    (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_12): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (13): Sequential(\n",
       "    (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_13): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (14): Sequential(\n",
       "    (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_14): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (15): Sequential()\n",
       "  (16): Sequential(\n",
       "    (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_16): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (17): Sequential(\n",
       "    (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_17): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (18): Sequential()\n",
       "  (19): Sequential(\n",
       "    (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_19): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (20): Sequential(\n",
       "    (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_20): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (21): Sequential()\n",
       "  (22): Sequential(\n",
       "    (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_22): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (23): Sequential(\n",
       "    (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_23): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (24): Sequential()\n",
       "  (25): Sequential(\n",
       "    (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_25): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (26): Sequential(\n",
       "    (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_26): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (27): Sequential()\n",
       "  (28): Sequential(\n",
       "    (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_28): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (29): Sequential(\n",
       "    (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_29): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (30): Sequential()\n",
       "  (31): Sequential(\n",
       "    (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_31): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (32): Sequential(\n",
       "    (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_32): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (33): Sequential()\n",
       "  (34): Sequential(\n",
       "    (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_34): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (35): Sequential(\n",
       "    (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_35): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (36): Sequential()\n",
       "  (37): Sequential(\n",
       "    (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_37): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (38): Sequential(\n",
       "    (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_38): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (39): Sequential(\n",
       "    (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_39): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (40): Sequential()\n",
       "  (41): Sequential(\n",
       "    (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_41): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (42): Sequential(\n",
       "    (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_42): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (43): Sequential()\n",
       "  (44): Sequential(\n",
       "    (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_44): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (45): Sequential(\n",
       "    (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_45): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (46): Sequential()\n",
       "  (47): Sequential(\n",
       "    (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_47): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (48): Sequential(\n",
       "    (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_48): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (49): Sequential()\n",
       "  (50): Sequential(\n",
       "    (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_50): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (51): Sequential(\n",
       "    (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_51): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (52): Sequential()\n",
       "  (53): Sequential(\n",
       "    (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_53): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (54): Sequential(\n",
       "    (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_54): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (55): Sequential()\n",
       "  (56): Sequential(\n",
       "    (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_56): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (57): Sequential(\n",
       "    (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_57): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (58): Sequential()\n",
       "  (59): Sequential(\n",
       "    (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_59): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (60): Sequential(\n",
       "    (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_60): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (61): Sequential()\n",
       "  (62): Sequential(\n",
       "    (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_62): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (63): Sequential(\n",
       "    (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_63): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (64): Sequential(\n",
       "    (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_64): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (65): Sequential()\n",
       "  (66): Sequential(\n",
       "    (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_66): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (67): Sequential(\n",
       "    (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_67): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (68): Sequential()\n",
       "  (69): Sequential(\n",
       "    (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_69): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (70): Sequential(\n",
       "    (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_70): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (71): Sequential()\n",
       "  (72): Sequential(\n",
       "    (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_72): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (73): Sequential(\n",
       "    (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_73): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (74): Sequential()\n",
       "  (75): Sequential(\n",
       "    (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_75): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (76): Sequential(\n",
       "    (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_76): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (77): Sequential(\n",
       "    (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_77): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (78): Sequential(\n",
       "    (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_78): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (79): Sequential(\n",
       "    (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_79): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (80): Sequential(\n",
       "    (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_80): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (81): Sequential(\n",
       "    (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (82): Sequential()\n",
       "  (83): Sequential()\n",
       "  (84): Sequential(\n",
       "    (conv_84): Conv2d(255, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_84): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (85): Sequential(\n",
       "    (upsample_85): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  )\n",
       "  (86): Sequential()\n",
       "  (87): Sequential(\n",
       "    (conv_87): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_87): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (88): Sequential(\n",
       "    (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_88): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (89): Sequential(\n",
       "    (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_89): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (90): Sequential(\n",
       "    (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_90): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (91): Sequential(\n",
       "    (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_91): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (92): Sequential(\n",
       "    (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_92): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (93): Sequential(\n",
       "    (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (94): Sequential()\n",
       "  (95): Sequential()\n",
       "  (96): Sequential(\n",
       "    (conv_96): Conv2d(255, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_96): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (97): Sequential(\n",
       "    (upsample_97): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  )\n",
       "  (98): Sequential()\n",
       "  (99): Sequential(\n",
       "    (conv_99): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_99): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (100): Sequential(\n",
       "    (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_100): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (101): Sequential(\n",
       "    (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_101): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (102): Sequential(\n",
       "    (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_102): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (103): Sequential(\n",
       "    (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_103): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (104): Sequential(\n",
       "    (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky_ReLu_104): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (105): Sequential(\n",
       "    (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (106): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_modules(parse_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'convolutional',\n",
       " 'batch_normalize': '1',\n",
       " 'filters': '32',\n",
       " 'size': '3',\n",
       " 'stride': '1',\n",
       " 'pad': '1',\n",
       " 'activation': 'leaky'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
